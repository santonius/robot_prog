{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e14883",
   "metadata": {},
   "source": [
    "# Exercise 4 -Computer Vision\n",
    "\n",
    "\n",
    "### 4.1 - Face Detection and Tracking\n",
    "In this task you will implement face detection and tracking using OpenCV. Specifically we are utilizing Cascade classifiers which implements Viola-Jones detection algorithm.\n",
    "\n",
    "**Reference**\n",
    "- [OpenCV documentation on cascade classifier](https://docs.opencv.org/master/db/d28/tutorial_cascade_classifier.html)\n",
    "\n",
    "### 4.1.1\n",
    "Execute the code below to initiate the cascadee classifier and the utility libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed45085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb82336",
   "metadata": {},
   "source": [
    "### 4.1.2\n",
    "\n",
    "Similar to Task 3, the first step is to obtain a frame from video file and pre-processing it. \n",
    "\n",
    "**Your task**\n",
    "\n",
    "Complete prep() function below which performs following using opencv and imutils libraries. The steps already implemented are marked with a tick \"âœ“\"\n",
    "\n",
    "- [x] Takes a frame from video feed as the input\n",
    "- [ ] Resize the frame while protecting the aspect ratio (width = 600) \n",
    "- [ ] Flip the image\n",
    "- [ ] Convert the frame to grayscale image\n",
    "- [x] Return grayscale image and resized image \n",
    "\n",
    "**References**\n",
    "\n",
    "- [imutils documentation](https://github.com/PyImageSearch/imutils#imutils)\n",
    "- [Fip an array with OpenCV](https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gaca7be533e3dac7feb70fc60635adf441)\n",
    "- [color conversion with OpenCV](https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce9f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(img):\n",
    "    ## ToDo 4.1.2\n",
    "    #  1. resize using  imutils.resize()\n",
    "    #  2. flip image using cv2.flip()\n",
    "    #  3. convert to gray color using cv2.cvtColor()\n",
    "    img = imutils.resize(img,width=600)\n",
    "    #img_flipped = cv2.flip(img,0)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return gray, img    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f056c",
   "metadata": {},
   "source": [
    "# 4.1.3\n",
    "\n",
    "In 4.1.1 we initialized an instance of cascade classifier. Tracking a face can be broken down into 3 steps as below\n",
    "\n",
    "1. Detect Faces and ROIs\n",
    "\n",
    "   The cascade classifier has a member function which can detect faces of multiple scales in a given image. The area where a face is detected becomes a region of interest (ROI) for extracting meaningful information. \n",
    "\n",
    "    **References** : \n",
    "    [Multiscale face detection member function of cascade classifier](https://docs.opencv.org/3.4/d1/de5/classcv_1_1CascadeClassifier.html#a90fe1b7778bed4a27aa8482e1eecc116)\n",
    "\n",
    "\n",
    "2. Extract trackable features \n",
    "\n",
    "    Shi-Tomasi Corner Detector is an implementation in openCV which extracts information from the ROI input. The extracted information are points on the face which are are trackable across a sequence of moving frames (a video).\n",
    "\n",
    "    **References** : \n",
    "    [OpenCV Trackable feature extraction function(Shi-Tomasi Corner Detector)](https://docs.opencv.org/4.5.2/d4/d8c/tutorial_py_shi_tomasi.html)\n",
    "\n",
    "\n",
    "3. Calculate the optical flow\n",
    "\n",
    "    These trackable points are used to calculate the optical flow of the faces with calcOpticalFlowPyrLK() function. The tracking is visualized via OpenCV drawing tools.\n",
    "\n",
    "    **References** : \n",
    "    - [Optical Flow calculation](https://docs.opencv.org/4.5.3/d4/dee/tutorial_optical_flow.html)\n",
    "    - [OpenCV drawing functions](https://docs.opencv.org/4.5.2/dc/da5/tutorial_py_drawing_functions.html)\n",
    "\n",
    "**Your task**\n",
    "\n",
    "Complete the function which perfoms following\n",
    "\n",
    "- [x] Takes grayscale image and resized image as the input\n",
    "- [x] Detect faces in graycale image using cascade classifier. detectMultiscale() function returns detected faces as rectangles ( Top left x coordinate, Top left y coordinate, width, height)\n",
    "- [ ] Draw a rectangle around detected faces using OpenCV drawing functions\n",
    "- [ ] Slice a region of interest (ROI) from grayecale image corresponding to the detections\n",
    "- [x] Extract good features to track (p0), from OpenCV goodFeaturesToTrack() function.\n",
    "- [ ] Convert the array p0 from current format [[[x1,y1],[x2,y2],....]] to --> [[x1,y1],[x2,y2],....]. Tip : print p0 to observe current format\n",
    "- [ ] The points are located with respect to the ROI coordinates. Convert them to image coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d3e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trackable_points(gray,img):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    p0 = []\n",
    "    if len(faces) != 0:\n",
    "        \n",
    "        rois = []\n",
    "        ## ToDO 4.1.3\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            roi_gray = gray[y:y+h,x:x+w]  \n",
    "            p0tmp = cv2.goodFeaturesToTrack(roi_gray,maxCorners=70,qualityLevel=0.001,minDistance=5)\n",
    "            p0tmp = p0tmp.reshape(-1,2)\n",
    "            p0tmp = [[x+corner[0],y+corner[1]] for corner in p0tmp]\n",
    "            rois.extend(p0tmp)\n",
    "        \n",
    "        p0 = rois\n",
    "        # ToDO 4.1.3\n",
    "        #  covert fromat of p0 to [[x1,y1],[x2,y2],....] \n",
    "        #  convert points from ROI to image coordinates\n",
    "   \n",
    "    p0 = np.array(p0,dtype=np.float32)\n",
    "\n",
    "    return p0, faces, img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6c1c4",
   "metadata": {},
   "source": [
    "**Your task**\n",
    "\n",
    "Complete the do_track_face() function which perfoms following\n",
    "\n",
    "- [x] Usecv2.calcOpticalFlowPyrLK()to calculate the optical flow for tracking face\n",
    "- [ ] Select the valid points from p1. Note that  isFound == 1 for valid points \n",
    "- [ ] Return the valid points as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6754539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_track_face(gray_prev, gray, p0):\n",
    "    p1, isFound, err = cv2.calcOpticalFlowPyrLK(gray_prev, gray, p0, \n",
    "                                                            None,\n",
    "                                                            winSize=(31,31),\n",
    "                                                            maxLevel=10,\n",
    "                                                            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03),\n",
    "                                                            flags=cv2.OPTFLOW_LK_GET_MIN_EIGENVALS,\n",
    "                                                            minEigThreshold=0.00025)\n",
    "    ## ToDo 4.1.3 - Select valid points from p1\n",
    "    # Select valid points from p0   \n",
    "    # return a numpy array of selected points from p0\n",
    "    valid = p1[(isFound ==1).ravel()]\n",
    "    #valid = p1[isFound ==1]\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740edad5",
   "metadata": {},
   "source": [
    "### 4.1.4\n",
    "\n",
    "Run the program to view the final output of face tracking. Remember to enter the correct path to video file provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844eda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 30\n",
    "prev = 0\n",
    "gray_prev = None\n",
    "p0 = []\n",
    "cam = cv2.VideoCapture(\"Face.mp4\")\n",
    "#cam = cv2.VideoCapture(0)\n",
    "\n",
    "if not cam.isOpened():\n",
    "    raise Exception(\"Could not open camera/file\")\n",
    "    \n",
    "while True:\n",
    "    time_elapsed = time.time() - prev\n",
    "    \n",
    "    if time_elapsed > 1./frame_rate:\n",
    "        \n",
    "        ret_val,img = cam.read()\n",
    "        \n",
    "        if not ret_val:\n",
    "                cam.set(cv2.CAP_PROP_POS_FRAMES, 0)  # restart viiideo\n",
    "                gray_prev = None  # previous frame\n",
    "                p0 = []  # previous points\n",
    "                continue\n",
    "        prev = time.time()\n",
    "        \n",
    "        gray, img = prep(img)\n",
    "\n",
    "        if len(p0) <= 10: \n",
    "            p0, faces, img = get_trackable_points(gray,img)\n",
    "        \n",
    "        else:\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                p1 = do_track_face(gray_prev, gray, p0)\n",
    "            for i in p1:\n",
    "                cv2.drawMarker(img, (round(i[0]), round(i[1])),[255,0,0],0)\n",
    "            p0 = p1\n",
    "        \n",
    "        gray_prev = gray.copy()\n",
    "        cv2.imshow('Video feed', img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "              \n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b856faf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m     rclpy\u001b[38;5;241m.\u001b[39minit(args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m     image_subscriber \u001b[38;5;241m=\u001b[39m Get_Images() \n\u001b[0;32m---> 69\u001b[0m     \u001b[43mrclpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_subscriber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# executes on keyboard kernal interrupt with double pressing button \"i\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     image_subscriber\u001b[38;5;241m.\u001b[39mstop_stream()\n",
      "File \u001b[0;32m/opt/ros/foxy/lib/python3.8/site-packages/rclpy/__init__.py:191\u001b[0m, in \u001b[0;36mspin\u001b[0;34m(node, executor)\u001b[0m\n\u001b[1;32m    189\u001b[0m     executor\u001b[38;5;241m.\u001b[39madd_node(node)\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mok():\n\u001b[0;32m--> 191\u001b[0m         \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspin_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     executor\u001b[38;5;241m.\u001b[39mremove_node(node)\n",
      "File \u001b[0;32m/opt/ros/foxy/lib/python3.8/site-packages/rclpy/executors.py:714\u001b[0m, in \u001b[0;36mSingleThreadedExecutor.spin_once\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    712\u001b[0m handler()\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler\u001b[38;5;241m.\u001b[39mexception() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m handler\u001b[38;5;241m.\u001b[39mexception()\n",
      "File \u001b[0;32m/opt/ros/foxy/lib/python3.8/site-packages/rclpy/task.py:239\u001b[0m, in \u001b[0;36mTask.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39miscoroutine(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Execute a coroutine\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# The coroutine finished; store the result\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/ros/foxy/lib/python3.8/site-packages/rclpy/executors.py:429\u001b[0m, in \u001b[0;36mExecutor._make_handler.<locals>.handler\u001b[0;34m(entity, gc, is_shutdown, work_tracker)\u001b[0m\n\u001b[1;32m    426\u001b[0m gc\u001b[38;5;241m.\u001b[39mtrigger()\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m call_coroutine(entity, arg)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     entity\u001b[38;5;241m.\u001b[39mcallback_group\u001b[38;5;241m.\u001b[39mending_execution(entity)\n",
      "File \u001b[0;32m/opt/ros/foxy/lib/python3.8/site-packages/rclpy/executors.py:343\u001b[0m, in \u001b[0;36mExecutor._execute_timer\u001b[0;34m(self, tmr, _)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_timer\u001b[39m(\u001b[38;5;28mself\u001b[39m, tmr, _):\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m await_or_execute(tmr\u001b[38;5;241m.\u001b[39mcallback)\n",
      "File \u001b[0;32m/opt/ros/foxy/lib/python3.8/site-packages/rclpy/executors.py:118\u001b[0m, in \u001b[0;36mawait_or_execute\u001b[0;34m(callback, *args)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m callback(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Call a normal function\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [1], line 39\u001b[0m, in \u001b[0;36mGet_Images.timer_callback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m gray, img \u001b[38;5;241m=\u001b[39m \u001b[43mprep\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#if len(self.p0) <= 10 or self.frame_counter % 60 == 0: \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prep' is not defined"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "\n",
    "import sys\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from cv_bridge import CvBridge\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "#print(sys.path)\n",
    "\n",
    "bridge = CvBridge()\n",
    "\n",
    "class Get_Images(Node):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize the node\n",
    "        super().__init__('Image_Subscriber')\n",
    "        # Initialize the subscriber\n",
    "        self.subscription_ = self.create_subscription( Image,'/image_raw', self.listener_callback,10)\n",
    "        self.subscription_  # prevent unused variable warning\n",
    "        timer_period = 0.1  # seconds\n",
    "        self.timer = self.create_timer(timer_period, self.timer_callback)\n",
    "        self.p0 = []\n",
    "        self.frame_counter = 0\n",
    "        self.frame = None\n",
    "\n",
    "    def listener_callback(self, msg):\n",
    "        height = msg.height\n",
    "        width = msg.width\n",
    "        channel = msg.step//msg.width\n",
    "        #frame = np.reshape(msg.data, (height, width, channel))\n",
    "        self.frame =  bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n",
    "        return self.frame\n",
    "    \n",
    "    def timer_callback(self):\n",
    "        if self.frame is None:\n",
    "            return\n",
    "        gray, img = prep(self.frame)\n",
    "        self.frame_counter += 1\n",
    "        \n",
    "\n",
    "        #if len(self.p0) <= 10 or self.frame_counter % 60 == 0: \n",
    "        p0, faces, img = get_trackable_points(gray,img)\n",
    "        self.p0 = p0\n",
    "        gray_prev = gray.copy()\n",
    "        self.frame_counter = 0\n",
    "        #else:\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            p1 = do_track_face(gray_prev, gray, self.p0)\n",
    "            for i in p1:\n",
    "                cv2.drawMarker(img, (round(i[0]), round(i[1])),[255,0,0],0)\n",
    "            self.p0 = p1\n",
    "\n",
    "\n",
    "        gray_prev = gray.copy()\n",
    "        cv2.imshow('Video feed', img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                \n",
    "    def stop_stream(self):\n",
    "        self.get_logger().info('Stopping the stream ...')\n",
    "        \n",
    "\n",
    "try:\n",
    "    rclpy.init(args=None)\n",
    "    image_subscriber = Get_Images() \n",
    "    rclpy.spin(image_subscriber)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # executes on keyboard kernal interrupt with double pressing button \"i\"\n",
    "    image_subscriber.stop_stream()\n",
    "    image_subscriber.destroy_node()\n",
    "    rclpy.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracker",
   "language": "python",
   "name": "tracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
